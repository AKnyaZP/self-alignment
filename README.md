# Self-Alignment with LLM for Russian Instructions

## Описание
Этот проект использует датасет  <a href='https://huggingface.co/datasets/OpenAssistant/oasst1'>OpenAssistant/oasst1</a> для обучения модели LLM, которая генерирует ответы на русскоязычные инструкции. Основная цель проекта — исследовать подходы к выравниванию модели (self-alignment) для достижения определенного стиля ответов.


## Структура проекта
- `data/`: Директория для хранения данных (не включены в репозиторий). Датасеты с инструкциями на русском языке.
- `data/data4alignment`: В этой директории хранятся данные именно для выравнивания модели. 
- `notebooks/`:  `/eda.ipynb`- ноутбук с **EDA** и **визуализацией данных**, а также `/data4alignment.ipynb` - ноутбук с созданием **датасета для элаймента**, посредством *генерации ответов* на инструкции и их *оценкой* по критериям из таблицы (в качестве *label* я использовал *усреднённую оценку* ответа по всем заданным критериям).
- `src/`: Основной код для обучения, генерации ответов и оценки модели.
- `experiments/`: эксперименты и результаты
- `models/`: здесь хранится дообученная модель


## Достигаться будет стиль кратких и содержательных ответов

#### Улучшение качества ответов:
* Короткие и полезные ответы чаще всего содержат наиболее важную и релевантную информацию.
* Их легче читать и понимать, что особенно важно для широкого круга пользователей.
#### Повышение эффективности:
* Более краткие ответы дают пользователю возможность быстрее получить нужную информацию.
* Это особенно важно в контексте диалоговых систем, где время ответа критично.
#### Улучшение пользовательского опыта:
* Короткие, но полезные ответы делают систему более дружелюбной и удобной для использования.
* Пользователи меньше вероятны будут чувствовать себя перегруженными избыточными данными.


## Шкала критериев  
### По этой шкале модель будет оценивать саму себя 

| Критерий      | Описание                                                                                                                                  | Оценка (по 5-балльной шкале) |
|---------------|--------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------|
| **Краткость** | Ответ содержит только необходимую информацию, без лишних деталей. <br> 5 — идеально краткий; 1 — перегружен ненужной информацией.           | 1-5                           |
| **Полезность**| Ответ полностью решает задачу или отвечает на вопрос. <br> 5 — полностью полезен; 1 — не имеет отношения к вопросу.                         | 1-5                           |
| **Точность**  | Ответ достоверен и корректен. <br> 5 — полностью точен; 1 — содержит ошибки.                                                               | 1-5                           |
| **Ясность**   | Ответ понятен и не содержит сложных формулировок или терминов, которые могут сбить с толку. <br> 5 — легко понять; 1 — запутан или неясен. | 1-5                           |
| **Лаконичность**| Ответ экономен в словах, избегает повторений и избыточности. <br> 5 — максимально лаконичен; 1 — многословен и избыточен.                  | 1-5                           |  

Для self-alignment модели мы используем инструкции на русском языке из датасета <a href='https://huggingface.co/datasets/OpenAssistant/oasst1'>OpenAssistant/oasst1</a>, а также ответы самой модели и её оценка по критериям из таблицы выше.  
Для генерации ответов и одновременной оценки этих ответов по шкале критериев, я использовал промпт, который модель получала на вход вместе с инструкцией:  

**PROMPT:**  
("Отвечай на русском языке. " + instruction + ". Дай краткий и содержательный ответ, затем оцени ответ от 1 до 5 по критериям: " +  
criteria + ". Важно! Ответ должен быть в таком формате: ответ, оценка от 1 до 5 без лишнего текста и символов.  
Не нужно вставлять объяснения ответа и его качества.")  

Рассмотрим этот промпт подробнее:
* `Отвечай на русском языке`: Эта часть важна в нашем запросе, так как *Gemma* может начать отвечать на английском, если инструкция содержит английские слова.
* `instruction`: Это входная инструкция, на которую должна отвечать наша языковая модель
* `Дай краткий и содержательный ответ, затем оцени ответ от 1 до 5 по критериям`: Здесь мы просим модель дать именно краткий и содержательный ответ, для его дальнейшей оценки
* `criteria`: Здесь хранятся все критерии, по которым нужно оценивать ответ модели
* `Важно! Ответ должен быть в таком формате: ответ, оценка от 1 до 5 без лишнего текста и символов. Не нужно вставлять объяснения ответа и его качества`  
  **или**
* `Важно! Ответ должен быть в формате JSON без лишнего текста: {\"answer\": \"[твой ответ]\", \"estimate\": [оценка от 1 до 5]}.`: эта часть промпта одна из самых главных. Здесь мы просим генерировать ответ в определённой форме для более просто извлечения самого ответа и его оценки.
     
## Установка и запуск
1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/username/project_name.git
   cd project_name
   
2. Установите зависимости:
   ```bash
   pip install -r requirements.txt
